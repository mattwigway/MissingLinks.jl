---
title: Build graph
author: Matt Bhagat-Conway
---

```{julia}
using GeoDataFrames, DataFrames, MissingLinks, Graphs, Mmap, ArchGDAL,
    MetaGraphsNext, CSV, Gadfly, StatsBase, DataFramesMeta
import Humanize: digitsep
import Cairo, Fontconfig # gadfly -> png
import TOML
import GeoFormatTypes as GFT
import Dates: now
CONFIG = TOML.parsefile(joinpath(dirname(@__FILE__), "..", "config.toml"))
DATA_PATH = CONFIG["data_path"]
DATAAXLE_PATH = CONFIG["dataaxle_path"]
```

## Read data

We currently have three data files we're working with: sidewalks, shared-use paths, and crosswalks.

```{julia}
# TODO clean up these paths
sidewalks = GeoDataFrames.read(joinpath(DATA_PATH, "data", "network", "charlotte_sidewalks_mwbc.gpkg"))
paths = GeoDataFrames.read(joinpath(DATA_PATH, "data", "network", "charlotte_shared_use_paths_mwbc.gpkg"))
crosswalks = GeoDataFrames.read(joinpath(DATA_PATH, "data", "network", "charlotte_crosswalks_split_mwbc.gpkg"))

# there are some new crosswalks since the 2019 Mecklenburg imagery. Including all of them is not
# practical. However, ones that are identified as priority links are included in this file.
new_crosswalks = GeoDataFrames.read(joinpath(DATA_PATH, "data", "network", "new_crosswalks_since_2019_mwbc.gpkg"))
rename!(new_crosswalks, :geometry => :geom)
```

The sidewalks layer has some curves, convert them to linestring

```{julia}
sidewalks.geom = ArchGDAL.lineargeom.(sidewalks.geom)
```

## Convert to noded

```{julia}
noded = semi_to_fully_noded(sidewalks, crosswalks, new_crosswalks, paths; snap_tolerance=3, split_tolerance=0.5)
```

## Build network

This builds a MetaGraphsNext network from the dataset.

```{julia}
G = graph_from_gdal(noded)
```

Now, we add short edges (<3.5 m) to connect the graph in places where there are small gaps due to data errors.

```{julia}
add_short_edges!(G, 3.5)
```

```{julia}
G = remove_tiny_islands(G, 10)
```

```{julia}
MissingLinks.graph_to_graphml(joinpath(DATA_PATH, "data", "graph.graphml"), G, pretty=true)
```


## Create origin and destination weights

```{julia}
parcels = GeoDataFrames.read(joinpath(DATA_PATH, "data", "parcels", "parcels_with_estimated_population.gpkg"));
# reproject state plane feet to meters
parcels.geom = reproject(parcels.geom, GFT.EPSG(2264), GFT.EPSG(32119));
parcels = parcels[.!ismissing.(parcels.est_pop), :]
metadata!(parcels, "geometrycolumns", (:geom,))
```

```{julia}
origin_weights = create_graph_weights(G, parcels, [:est_pop], 20)[:, 1]
```

Destinations are a little trickier because they're split across multiple files. We have a parcels file that has destinations snapped to parcels (for destinations that are likely to be in the middle of parcels), point features (for bus stops), and area features (neighborhood and regional parks).

```{julia}
dest_parcels = GeoDataFrames.read(joinpath(DATA_PATH, "data", "destinations", "weighted_parcels.gpkg"))

# already in EPSG:32119

dest_weights_snapped = create_graph_weights(G, dest_parcels, [:dest_weight], 20)[:, 1]

# What percent of weight successfully snapped? Expected to be less than one because not all parcels have sidewalk access
sum(dest_weights_snapped) / sum(dest_parcels.dest_weight)
```

```{julia}
dest_points_unsnapped = @chain begin
    GeoDataFrames.read(joinpath(DATAAXLE_PATH, "all_point_locations.gpkg"))
    @subset! .!:snap_to_parcels
end

dest_points_unsnapped.geom = reproject(dest_points_unsnapped.geom, GFT.EPSG(4326), GFT.EPSG(32119), order=:trad)

metadata!(dest_points_unsnapped, "geometrycolumns", (:geom,))

dest_weights_unsnapped = create_graph_weights(G, dest_points_unsnapped, [:weight], 20)[:, 1]

sum(dest_weights_unsnapped) / sum(dest_points_unsnapped.weight)
```

```{julia}
nbhd_parks = GeoDataFrames.read(joinpath(DATA_PATH, "data", "destinations", "neighborhood_parks.gpkg"))
regional_parks = GeoDataFrames.read(joinpath(DATA_PATH, "data", "destinations", "neighborhood_parks.gpkg"))
nbhd_parks.weight .= 2.0
regional_parks.weight .= 2.0
parks = vcat(nbhd_parks, regional_parks)
parks.geom = reproject(parks.geom, GFT.EPSG(2264), GFT.EPSG(32119))
metadata!(parks, "geometrycolumns", (:geom,))
dest_weights_parks = create_graph_weights(G, parks, [:weight], 20)[:, 1]

sum(dest_weights_parks) / sum(parks.weight)
```


Greenways have points placed along them. We use a much lower snapping tolerance since the points are placed using our source data directly.

```{julia}
greenway_points = GeoDataFrames.read(joinpath(DATA_PATH, "data", "destinations", "greenway_points.gpkg"))
dest_weights_greenway = create_graph_weights(G, greenway_points, [:weight], 1e-2)

# should be very close to 1
sum(dest_weights_greenway) / sum(greenway_points.weight)
```

```{julia}
dest_weights = dest_weights_snapped .+ dest_weights_unsnapped .+ dest_weights_parks .+ dest_weights_greenway
```

## Run the core algorithm

```{julia}
algorithm_start = now()
dfile = open("distances.bin", "w+")
matrix = Mmap.mmap(dfile, Matrix{UInt16}, (nv(G), nv(G)); grow=true)
fill!(matrix, zero(UInt16));
```

Do the routing

```{julia}
MissingLinks.fill_matrix!(G, matrix)
```

Find candidate missing links (places where network distance >> geographic distance)

```{julia}
all_candidate_links = identify_potential_missing_links(G, matrix, 100, 1000)
```

Deduplicate similar links (~5min)

```{julia}
candidate_links = deduplicate_links(all_candidate_links, matrix, 100)
```


## Score the links

```{julia}
scores = score_links(x -> x < 1609 * 2, candidate_links, matrix, origin_weights, dest_weights, 1609 * 2)
```

## Timing

```{julia}
runtime = now() - algorithm_start
println("Algorithm took $runtime")
```

### Score histogram

```{julia}
p = plot(
    DataFrame(:score=>scores),
    x=:score,
    Geom.histogram(bincount=50),
    Guide.xlabel("Aggregate accessibility impact"),
    Guide.ylabel("Number of links"),
    Scale.x_continuous(labels=x -> digitsep(round(Int64, x))))

draw(PNG(joinpath(DATA_PATH, "paper", "figures", "scores.png"), dpi=300), p)

p
```

```{julia}
median(scores)
```

```{julia}
mean(scores)
```

```{julia}
links_gis = links_to_gdf(G, candidate_links, scores)
GeoDataFrames.write(joinpath(DATA_PATH, "data", "candidate_missing_links.gpkg"), links_gis; crs=GFT.EPSG(32119));

# Note: link at 443397.71, 166211.30 has zero length reported but 0.26m in GIS. I assume this is because we round the offsets.
```

```{julia}
links_gis = links_to_gdf(G, all_candidate_links)
GeoDataFrames.write(joinpath(DATA_PATH, "data", "all_candidate_missing_links.gpkg"), links_gis; crs=GFT.EPSG(32119));
```

## Service area example (for NCAMPO slides)

Generate some service areas to better explain the algorithm.

```{julia}
edge_index = MissingLinks.index_graph_edges(G)
```

```{julia}
sources = [
    (name="North", geom=ArchGDAL.createpoint(444316.0,156853.7), link=1660),
    (name="South", geom=ArchGDAL.createpoint(444000.5,156368.8), link=1660),
]

service_areas = DataFrame(Iterators.flatmap(sources) do source
        [
            (
                name=source.name,
                which="Before",
                service_area(
                    source.geom,
                    G,
                    matrix,
                    1609 * 2,
                    scores=dest_weights,
                    edge_index=edge_index
                )...
            ),
            (
                name=source.name,
                which="After",
                service_area(
                    source.geom,
                    G,
                    matrix,
                    1609 * 2,
                    scores=dest_weights,
                    edge_index=edge_index,
                    links=[candidate_links[source.link]]
                )...
            )
        ]
    end
)

metadata!(service_areas, "geometrycolumns", (:geom,))

sources = DataFrame(sources)
metadata!(sources, "geometrycolumns", (:geom,))

GeoDataFrames.write(joinpath(DATA_PATH, "paper", "figures", "service_area_origins.gpkg"), sources, crs=GFT.EPSG(32119))
GeoDataFrames.write(joinpath(DATA_PATH, "paper", "figures", "service_areas.gpkg"), service_areas, crs=GFT.EPSG(32119))
```

```{julia}

```

```{julia}
close(dfile)
```
