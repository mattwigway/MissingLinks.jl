---
execute:
    echo: false
    include: false
format:
    pdf:
        geometry:
            - margin=1in
        fig-format: retina
fig-width: 3
fig-height: 1.5
---

```{julia}
using GeoDataFrames, DataFrames, DataFramesMeta, ArchGDAL, Plots, StatsBase, Gadfly
import TOML, Cairo, Fontconfig, Measures
import GeoFormatTypes as GFT
CONFIG = TOML.parsefile(joinpath(dirname(@__FILE__), "..", "..", "config.toml"))
DATA_PATH = CONFIG["data_path"]
```

```{julia}
old = GeoDataFrames.read(joinpath(DATA_PATH, "data", "candidate_missing_links_ceus.gpkg"))
new = GeoDataFrames.read(joinpath(DATA_PATH, "data", "candidate_missing_links.gpkg"))
```

```{julia}
for df in [old, new]
    df.frx = round.(ArchGDAL.getx.(df.geometry, 0))
    df.fry = round.(ArchGDAL.gety.(df.geometry, 0))
    df.tox = round.(ArchGDAL.getx.(df.geometry, 1))
    df.toy = round.(ArchGDAL.gety.(df.geometry, 1))
end
```

```{julia}
old100 = @chain old begin
    @subset :rank_2mi .≤ 100
end

new100 = @chain new begin
    @subset :rank_2mi .≤ 100
end
```

```{julia}
j = @chain old100 begin
    # dist from start too to try to break ties from coincident links
    innerjoin(new100, on=[:frx, :fry, :tox, :toy, :fr_dist_from_start, :to_dist_from_start], renamecols="_old"=>"_new")
end
```

```{julia}
jall = @chain old begin
    innerjoin(new, on=[:frx, :fry, :tox, :toy, :fr_dist_from_start, :to_dist_from_start], renamecols="_old"=>"_new")
end

@assert nrow(jall) == nrow(new)
```

```{julia}
# GIS visualization
crossed = jall[(jall.rank_2mi_old .≤ 100) .≠ (jall.rank_2mi_new .≤ 100), :]
crossed = @select(crossed, Not(:geometry_new))
GeoDataFrames.write(joinpath(DATA_PATH, "data", "links_over_boundary.gpkg"), crossed, geom_columns=(:geometry_old,), crs=GFT.EPSG(32119))
```

```{julia}
#| fig-width: 8
#| fig-height: 6
scatter(jall.score_2mi_old .+ 1, jall.score_2mi_new .+ 1, xaxis=:log, yaxis=:log, xlabel="Accessibility (as published)", ylabel="Accessibility (corrected)", legend=false, markersize=0.25)
```

```{julia}
histogram(jall.score_2mi_new .- jall.score_2mi_old)
```

```{julia}
histogram(jall.score_2mi_new ./ jall.score_2mi_old)
```

```{julia}
quantile((jall.score_2mi_new .+ 1) ./ (jall.score_2mi_old .+ 1), [0.05, 0.25, 0.5, 0.75, 0.95])
```

```{julia}
# newly in top 100
jall[(jall.rank_2mi_new .≤ 100) .&& (jall.rank_2mi_old .> 100), [:rank_2mi_new, :rank_2mi_old]]
```

```{julia}
# No longer in top 100
jall[(jall.rank_2mi_new .> 100) .&& (jall.rank_2mi_old .≤ 100), [:rank_2mi_new, :rank_2mi_old]]
```

```{julia}
corspearman(jall.score_2mi_new, jall.score_2mi_old)
```

```{julia}
new_old_cor = round(cor(jall.score_2mi_new, jall.score_2mi_old) * 100, digits=1)
```

My article "So close, yet so far: a new method for identification of high-impact missing links in pedestrian networks" was published in CEUS this past summer. The article introduced an algorithm to identify places where adding a link to a pedestrian network could increase connectivity, and provided a case study in Charlotte, North Carolina. In further work, I realized that there is an error in the supplemental materials, that affects only the case study. In scoring links, we use a variety of destination types, which are listed in the supplemental materials. I discovered two of the destination types, retail and civic, listed in the supplemental materials were not used in the results presented in the case study, and one of the sports and entertainment venues was also not included.

This does not undermine the scientific validity of the algorithm itself, which is the primary focus of the paper, as impacts are limited to the case study. Furthermore, even the case study is only very slightly affected. No interpretations are affected by the change. The key results including vs. excluding these destinations are correlated `{julia} new_old_cor`%, which is likely why I didn't notice it at time of submission (details of the differences are below). Retail is a large number of destinations, but they are spatially distributed very similarly to other destination types so conclusions are unaffected.

I am unsure whether this necessitates a correction, as the article is primarily about the algorithm rather than the example results, but wanted to be transparent. If it does necessitate a correction, either the supplemental materials or the article text could be corrected. Correcting the supplemental materials might be preferable as it would preserve the scientific record, and the results in the case study are not incorrect from the standpoint of demonstrating the algorithm.

## Details of all changes to results

The main score used in the case study is the aggregate accessibility within two miles. This score is correlated `{julia} new_old_cor`% between the results presented in the publication and these updated ones.

```{julia}
# some actually see a decrease on the order of less than 1e-6, but that's numerical issues
@assert all(jall.score_2mi_new .+ 1e-6 .> jall.score_2mi_old)
```

Scores are expected to go up as there are additional destinations. Indeed, no link shows a decrease in score. However, scores are primarily interpretable in comparison to one another, so an across-the-board increase is not problematic for interpretations. The plot below shows the relationship between the link score for each link in the original publication and with the additional destinations; while scores have increased somewhat, there is almost no change in the relationship.

```{julia}
#| output: true
#| include: true
#| fig-width: 8
#| fig-height: 6
scatter(jall.score_2mi_old, jall.score_2mi_new, xlabel="As published", ylabel="With additional destinations", legend=false, markersize=0.25, margin=10mm)
```

There are three other accessibility metrics used in robustness checks: a one-mile and three-mile cutoff, and a negative-exponential metric.  The one-mile metric is a little more noisy due to the generally smaller values, but all show the same trend of near perfect correlation between the published value and those including the additional destinations.

```{julia}
#| output: true
#| include: true

Plots.plot(
    scatter(jall.score_1mi_old, jall.score_1mi_new, xlabel="As published", ylabel="With additional destinations", title="One mile", legend=false, markersize=0.25),
    scatter(jall.score_3mi_old, jall.score_3mi_new, xlabel="As published", ylabel="With additional destinations", title="Three mile", legend=false, markersize=0.25),
    scatter(jall.score_negexp_old, jall.score_negexp_new, xlabel="As published", ylabel="With additional destinations", title="Negative exponential", legend=false, markersize=0.25),
    layout=(2, 2),
    margin=10mm
)

```

### Line-by-line differences

Text from original article is indented and italicized.

> _The algorithm identified 133,246 potential missing links; after the deduplication process, 2777 were retained, with a maximum aggregate accessibility impact of 350,000 households multiplied by destinations within two miles walk, a mean of 15,000, and a median of 4300. The full distribution of accessibility impacts is shown in Fig. 4. There are a few very high-value links, and many more of medium value._

```{julia}
@assert round(maximum(jall.score_2mi_old), digits=-4) ≈ 350_000
# rounding
@assert all(jall.score_2mi_new .+ 1e-6 .≥ jall.score_2mi_old)
newmax = round(maximum(jall.score_2mi_new), digits=-4)

@assert round(mean(jall.score_2mi_old), sigdigits=2) ≈ 15_000
newmean = round(mean(jall.score_2mi_new), sigdigits=2)

@assert round(median(jall.score_2mi_old), sigdigits=2) ≈ 4_300
newmedian = round(median(jall.score_2mi_new), sigdigits=2)
```

The number of identified links and deduplicated links are unchanged. The maximum aggregate accessibility impact is now `{julia} newmax`, with a mean of `{julia} newmean` and median of `{julia} newmedian`.

The histogram of accessibility scores is almost imperceptibly different.

Original:

```{julia}
#| output: true
#| include: true
Gadfly.plot(
    jall,
    x=:score_2mi_old,
    Geom.histogram(bincount=50),
    Guide.xlabel("Aggregate accessibility impact"),
    Guide.ylabel("Number of links"),
    Scale.x_continuous(labels=x -> "$(round(Int64, x))"))
```

Updated:

```{julia}
#| output: true
#| include: true
Gadfly.plot(
    jall,
    x=:score_2mi_new,
    Geom.histogram(bincount=50),
    Guide.xlabel("Aggregate accessibility impact"),
    Guide.ylabel("Number of links"),
    Scale.x_continuous(labels=x -> "$(round(Int64, x))"))
```

> _Fig. 5 shows the top 100 links identified in the region. The links are spread regionally, but many are approximately 1–2 miles from Uptown Charlotte (the Charlotte central business district). This is unsurprising, given that our accessibility metric accounts for destinations within 2 miles, though it does suggest that the algorithm is sensitive to the distance cutoff chosen. Quite a few links are effectively duplicates, but were not filtered by the deduplication algorithm as they were not part of the same sphere of influence (for example, the links shown in red in Fig. 2)._

```{julia}
cp(joinpath(DATA_PATH, "paper", "figures", "top100.png"), "figures/top100.png", force=true)
cp(joinpath(DATA_PATH, "paper", "figures", "top100_updated.png"), "figures/top100_updated.png", force=true)
```

![Original map](figures/top100.png)

![Updated map (note: extent expanded to include a link that was in the top 100 but was cut off by extent in original paper)](figures/top100_updated.png)

```{julia}
nchange = sum(jall.rank_2mi_old .≤ 100 .&& jall.rank_2mi_new .≤ 100)
highestold = round(Int64, minimum(jall.rank_2mi_old[jall.rank_2mi_old .≤ 100 .&& jall.rank_2mi_new .> 100]))
lowestnew = round(Int64, maximum(jall.rank_2mi_old[jall.rank_2mi_old .> 100 .&& jall.rank_2mi_new .≤ 100]))

near100 = jall[jall.rank_2mi_old .>= 85 .&& jall.rank_2mi_old .<= 115, :score_2mi_old]
```

Of the 100 top-ranked links in the publication, `{julia} nchange` are still in the top 100 when including the additional destinations. There is not a lot of differentiation between link scores around the 100th-ranked link, so it is not unexpected that small changes in score might cause rank shift; in the original publication, the 85th-highest-scoring link has a score of `{julia} round(Int64, maximum(near100))`, and the 115th has a score of `{julia} round(Int64, minimum(near100))`. The highest-ranked link in the original publication that is no longer in the top 100 was `{julia} highestold`. The lowest-ranked link in the original publication that is now in the top 100 was `{julia} lowestnew`, which sees such a large improvement due to a nearby outlet mall with dozens of retail destinations. The plot below shows how the original ranks map on to the updated ranks, for the 250 highest-rated links.

```{julia}
#| output: true
#| include: true
jall.y .= 1
jall.yend .= 0

Gadfly.plot(
    jall[!, [:rank_2mi_old, :rank_2mi_new, :y, :yend]],
    x=:rank_2mi_old,
    xend=:rank_2mi_new,
    y=:y,
    yend=:yend,
    Geom.segment,
    Coord.cartesian(xmin=1, xmax=250),
    Guide.ylabel(""),
    Guide.yticks(label=false),
    Guide.xlabel("Updated rank"),
    Guide.title("Original rank"),
    Guide.xticks(ticks=0:25:250)
)
```

> _We manually reviewed the top-ranked 100 links, and grouped them into 41 groups of links that provide approximately the same access. Of these, 31 represented gaps best closed by new crossings, and 11 represented gaps in sidewalks. Four represented new off-street paths. Two links would require bridges or other vertical infrastructure. Some links fell into multiple categories._
>
> _All but one fell within existing public right-of-way. Four crossed railroad infrastructure, potentially making planning and permitting more difficult._

Given slight changes to the top 100 links, there will be similar slight changes to this result. I have not evaluated them as this is a manual process, but if a correction to the article text is desired I will.

<!-- no changes to fig 6 - the point locations were fine it was just the parcel snapping that was incorrect -->

> _The most highly ranked road crossing is at a railroad crossing on Louise Avenue, just outside uptown, and is shown in Fig. 6a. On the south side of the tracks, the sidewalk is on the west side of the street; it transitions to the east side north of the tracks. There is no marked crossing of the street or the tracks. Closing this gap would connect residents north of the tracks with significant opportunities in the uptown area to the south. This link has an accessibility score of 350,000._

This is still the most highly ranked road crossing, now with a score of 374,600.

> _The most highly ranked sidewalk gap is on Mallard Creek Church Road west of Tryon Street (Fig. 6b), with an accessibility score of 254,400—i.e. 73 % as much accessibility impact as the highest scoring project._

This is still the most highly ranked sidewalk gap, now with a score of 326,700, 87 % as high as the highest scoring project.

> _The most highly ranked new off-street connection that is not better served by a sidewalk on a parallel street is a connection between Commonwealth Avenue and the intersection of Wendover and Independence Avenues, a connection that was previously present but removed when a cloverleaf interchange was installed. This link has an accessibility score of 121,900 (i.e. 35 % as much as the highest scoring project)._

This is still the most highly ranked off-street connection not better served by a sidewalk on an adjacent road, now with a score of 148,300, 40 % as high as the highest scoring project.

> _The first example given above (the crossing of Louise Ave) ranks as the highest access improvement by the one and two mile metrics, as well as the negative exponential, but ranks 59th by the three-mile metric._

```{julia}
jall[jall.rank_2mi_old .== 1, [:rank_1mi_new, :rank_2mi_new, :rank_3mi_new, :rank_negexp_new]]
```

The crossing of Louise Avenue remains the highest access improvement by the two-mile and negative exponential metrics. It is now the second-highest by the one-mile metric, and the 62nd by the 3-mile metric.

> _Of the top 100 links identified by the two-mile cutoff, 43, 63, and 62 were in the top 100 for the one-mile, three-mile, and negative exponential forms, respectively._

```{julia}
top100 = jall[jall.rank_2mi_new .≤ 100, :]
in_1mi = sum(top100.rank_1mi_new .≤ 100)
in_3mi = sum(top100.rank_3mi_new .≤ 100)
in_negexp = sum(top100.rank_negexp_new .≤ 100)
```

These numbers are now `{julia} in_1mi`, `{julia} in_3mi`, and `{julia} in_negexp`, respectively, making the point about considering multiple functional forms marginally stronger.

> _Pairwise Spearman rank correlations between the scores for all links were 0.63 or higher._

```{julia}
cors = corspearman(Matrix{Float64}(jall[:, [:score_1mi_new, :score_2mi_new, :score_3mi_new, :score_negexp_new]]))
```

With the updated destinations, all Spearman rank correlations are `{julia} floor(minimum(cors), digits=2)` or higher.